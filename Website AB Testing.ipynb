{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze A/B Test Results \n",
    "\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "- [Final Check](#finalcheck)\n",
    "- [Submission](#submission)\n",
    "\n",
    "<a id='intro'></a>\n",
    "\n",
    "\n",
    "\n",
    "## Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "random.seed(42) #Set a seed for replicable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We'll store the a/b data in a Pandas DataFrame. Below is the description of the data, there are a total of 5 columns:\n",
    "\n",
    "<center>\n",
    "\n",
    "|Data columns|Purpose|Valid values|\n",
    "| ------------- |:-------------| -----:|\n",
    "|user_id|Unique ID|Int64 values|\n",
    "|timestamp|Time stamp when the user visited the webpage|-|\n",
    "|group|In the current A/B experiment, the users are categorized into two broad groups. <br>The `control` group users are expected to be served with `old_page`; and `treatment` group users are matched with the `new_page`. <br>However, **some inaccurate rows** are present in the initial data, such as a `control` group user is matched with a `new_page`. |`['control', 'treatment']`|\n",
    "|landing_page|It denotes whether the user visited the old or new webpage.|`['old_page', 'new_page']`|\n",
    "|converted|It denotes whether the user decided to pay for the company's product. Here, `1` means yes, the user bought the product.|`[0, 1]`|\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ab_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294478, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['converted'] == 1).sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1965"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[df['group'] == 'treatment']['landing_page'] != 'new_page').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: almost 300k rows, some user_id's are duplicates, about 11.97% of all rows have a converted value of 1, some subjects are in the wrong landing page group, and there are no null values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addressing the \"incorrect\" groups, the **group** and **landing_page** columns should have either of the following acceptable values:\n",
    "\n",
    "|user_id| timestamp|group|landing_page|converted|\n",
    "|---|---|---|---|---|\n",
    "|XXXX|XXXX|`control`| `old_page`|X |\n",
    "|XXXX|XXXX|`treatment`|`new_page`|X |\n",
    "\n",
    "\n",
    "It means, the `control` group users should match with `old_page`; and `treatment` group users should matched with the `new_page`. \n",
    "\n",
    "However, for the rows where `treatment` does not match with `new_page` or `control` does not match with `old_page`, we cannot be sure if such rows truly received the new or old wepage.  We'll address this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the inaccurate rows, and store the result in a new dataframe df2\n",
    "df2 = df.query('(group == \"control\" and landing_page == \"old_page\")or(group == \"treatment\" and landing_page == \"new_page\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the incorrect rows were removed from df2 - \n",
    "# Output of the statement below should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll take a look again at duplicate user ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['user_id'].duplicated(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['user_id'].duplicated(keep=False),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamp is different, but it's still a duplicate. Since the group and landing pages match, we'll just remove one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a840b573f4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2893\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Remove one of the rows with a duplicate user_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Verify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "df2 = df2.drop(2893) #Remove one of the rows with a duplicate user_id\n",
    "df2.loc[df2['user_id'].duplicated(keep=False),:] #Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo 1.4  \n",
    "\n",
    "\n",
    "What is the probability of an individual converting regardless of the page they receive?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_population = df2['converted'].mean()\n",
    "p_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_control = df2.query('group == \"control\"')['converted'].mean()\n",
    "p_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_treatment = df2.query('group == \"treatment\"')['converted'].mean()\n",
    "p_treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the observed difference in our sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_treatment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-de959805c339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobs_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_treatment\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp_control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mobs_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_treatment' is not defined"
     ]
    }
   ],
   "source": [
    "obs_diff = p_treatment - p_control\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50006194422266881"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new_page = (df2['group'] == 'treatment').mean()\n",
    "p_new_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that there's an even distribution between the control and treatment groups, and being in the treatment group actually lead to a decrease in conversion by 0.16%, we can conclude that based on our dataset, being in the treatment group, or being lead to the new page, does not lead to a higher conversion rate on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "## Part II - A/B Test\n",
    "\n",
    "Since a timestamp is associated with each event, we could run a hypothesis test continuously as long as you observe the events. \n",
    "\n",
    "However, then the hard questions would be: \n",
    "- Do we stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  \n",
    "- How long do we run to render a decision that neither page is better than another?  \n",
    "\n",
    "\n",
    "For now, we'll make the decision just based on all of the data provided at the time of procurement. .  \n",
    "\n",
    "We assume that the the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, meaning that our null hypothesis would be: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$ H_0: p_{new} - p_{old} \\leq 0$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Under the null hypothesis $H_0$, we assume that $p_{new}$ and $p_{old}$ are equal. Furthermore, we assume that $p_{new}$ and $p_{old}$ both are equal to the **converted** success rate in the `df2` data regardless of the page. So, our assumption is: <br><br>\n",
    "<center>\n",
    "$p_{new}$ = $p_{old}$ = $p_{population}$\n",
    "</center>\n",
    "\n",
    "In this section, we'll complete the following: \n",
    "\n",
    "- Simulate (bootstrap) sample data set for both groups, and compute the  \"converted\" probability $p$ for those samples. \n",
    "\n",
    "\n",
    "- Use a sample size for each group equal to the ones in the `df2` data.\n",
    "\n",
    "\n",
    "- Compute the difference in the \"converted\" probability for the two samples above. \n",
    "\n",
    "\n",
    "- Perform the sampling distribution for the \"difference in the converted probability\" between the two simulated-samples over 10,000 iterations; and calculate an estimate. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take our population conversion rate calculated before and assign its value\n",
    "# to p_new\n",
    "p_new = p_population\n",
    "p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take our population conversion rate calculated before and assign its value\n",
    "# to p_old\n",
    "\n",
    "p_old = p_population\n",
    "p_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new = (df2['landing_page'] == 'new_page').sum()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old = (df2['landing_page'] == 'old_page').sum()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulate Sample for the `treatment` Group**<br> \n",
    "\n",
    "We'll simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null hypothesis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate a Sample for the treatment Group\n",
    "new_page_converted = np.random.choice([0,1],p=[1-p_new, p_new],size=n_new)\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulate Sample for the `control` Group** <br>\n",
    "\n",
    "We'll simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate a Sample for the control Group\n",
    "old_page_converted = np.random.choice([0,1],p=[1-p_old,p_old],size=n_old)\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now find difference in the \"converted\" probability $(p{'}_{new}$ - $p{'}_{old})$ for the simulated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0008721252960417e-05"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.mean() - old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Sampling distribution** <br>\n",
    "To create a nice normal distribution under the null, we re-create `new_page_converted` and `old_page_converted` and find the $(p{'}_{new}$ - $p{'}_{old})$ value 10,000 times using the same simulation process you used before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling distribution\n",
    "p_diffs = []\n",
    "\n",
    "for i in range(10000):\n",
    "    sample_p_new = np.random.choice([0,1],p=[1-p_new, p_new],size=n_new)\n",
    "    sample_p_old = np.random.choice([0,1],p=[1-p_old,p_old],size=n_old)\n",
    "    p_diff = sample_p_new.mean() - sample_p_old.mean()\n",
    "    p_diffs.append(p_diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Difference in sampled means')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72c599ecc0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs)\n",
    "plt.axvline(x=obs_diff, color='r', label='huh')\n",
    "plt.xlabel('p_new - p_old')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Difference in sampled means')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What proportion of the **p_diffs** are greater than the actual difference observed in the `df2` data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9099"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater_than_obs_diff = []\n",
    "\n",
    "for i in range(len(p_diffs)):\n",
    "    if p_diffs[i] > obs_diff:\n",
    "        greater_than_obs_diff.append(p_diffs[i])\n",
    "\n",
    "proportion_greater = len(greater_than_obs_diff)/len(p_diffs)\n",
    "proportion_greater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "0.9099 would be the ***p-value***, which signifies how likely we are to observe our findings from the samples given the assumption that the null hypothesis holds true.\n",
    "\n",
    "If our Type I error rate is 0.05, we require a p-value less than or equal to 5% in order to reject our null hypothesis. In the context of our test results, 0.91 is much higher than 0.05, so we fail to reject the null hypothesis. Our p-value signfies that it is extremely likely that the observed difference from the previous section would have been observed under our null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Turning to Built-in Methods for Hypothesis Testing**<br>\n",
    "We could also use a built-in to achieve similar results.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# number of conversions with the old_page\n",
    "convert_old = (df2[df2['group'] == \"control\"]['converted'] == 1).sum()\n",
    "\n",
    "# number of conversions with the new_page\n",
    "convert_new = (df2[df2['group'] == \"treatment\"]['converted'] == 1).sum()\n",
    "\n",
    "# number of individuals who were shown the old_page\n",
    "n_old = (df2['group'] == \"control\").sum()\n",
    "\n",
    "# number of individuals who received new_page\n",
    "n_new = (df2['group'] == \"treatment\").sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sm.stats.proportions_ztest()`, we can compute the test statistic and p-value. The syntax is: \n",
    "```bash\n",
    "proportions_ztest(count_array, nobs_array, alternative='larger')\n",
    "```\n",
    "where, \n",
    "- `count_array` = represents the number of \"converted\" for each group\n",
    "- `nobs_array` = represents the total number of observations (rows) in each group\n",
    "- `alternative` = choose one of the values from `[‘two-sided’, ‘smaller’, ‘larger’]` depending upon two-tailed, left-tailed, or right-tailed respectively. \n",
    "\n",
    "\n",
    "The built-in function above will return the z_score, p_value. \n",
    "\n",
    "Another way for comparing the mean of two independent and normal distribution is a **two-sample z-test**. We can perform the Z-test to calculate the Z_score, as shown in the equation below:\n",
    "\n",
    "$$\n",
    "Z_{score} = \\frac{ (p{'}_{new}-p{'}_{old}) - (p_{new}  -  p_{old})}{ \\sqrt{ \\frac{\\sigma^{2}_{new} }{n_{new}} + \\frac{\\sigma^{2}_{old} }{n_{old}}  } }\n",
    "$$\n",
    "\n",
    "where,\n",
    "- $p{'}$ is the \"converted\" success rate in the sample\n",
    "- $p_{new}$ and $p_{old}$ are the \"converted\" success rate for the two groups in the population. \n",
    "- $\\sigma_{new}$ and $\\sigma_{new}$ are the standard deviation for the two groups in the population. \n",
    "- $n_{new}$ and $n_{old}$ represent the size of the two groups or samples (it's same in our case)\n",
    "\n",
    "\n",
    ">Z-test is performed when the sample size is large, and the population variance is known. The z-score represents the distance between the two \"converted\" success rates in terms of the standard error. \n",
    "\n",
    "Next step is to make a decision to reject or fail to reject the null hypothesis based on comparing these two values: \n",
    "- $Z_{score}$\n",
    "- $Z_{\\alpha}$ or $Z_{0.05}$, also known as critical value at 95% confidence interval.  $Z_{0.05}$ is 1.645 for one-tailed tests,  and 1.960 for two-tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.31092419842 0.905058312759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# ToDo: Complete the sm.stats.proportions_ztest() method arguments\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_new, convert_old], [n_new,n_old], alternative='larger')\n",
    "print(z_score, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $Z_{score}$ and p-value calculated by statsmodels' proportions_ztest supports our failure to reject the null hypothesis earlier.  The $Z_{score}$ of -1.311 is less than $Z_{\\alpha}$, which is 1.645.  Additionally, our p-value of 0.905 is much higher than the required value of 0.05 to reject the null hypothesis, and thus we fail to reject it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "In this final part, will experiment with replicating the results of the A/B test above by instead performing regression, specifically logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['intercept'] = 1\n",
    "df2[['not_ab_page','ab_page']] = pd.get_dummies(df2['group'])\n",
    "df2 = df2.drop('not_ab_page',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use statsmodels to instantiate the regression model on the two columns created above, then fit the model to predict whether or not an individual converts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-06-01 10:40</td>       <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2022-06-01 10:40 AIC:              212780.3502\n",
       "No. Observations:   290584           BIC:              212801.5095\n",
       "Df Model:           1                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290582           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9888    0.0081  -246.6690  0.0000  -2.0046  -1.9730\n",
       "ab_page      -0.0150    0.0114    -1.3109  0.1899  -0.0374   0.0074\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df2['converted'],df2[['intercept','ab_page']])\n",
    "results = logit_mod.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98511193960306265"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-.015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The coefficient of ab_page and in the summary and its resulting exponentiated value of 0.986 indicates that if the individual is in the treatment group, they are 0.985x as likely (or in other words, slightly less likely) to convert in comparision to individuals who are in the control group. Our p-value is 0.19, and its difference from our previous p-values results from the fact that the logistic regression model is testing a two-sided hypothesis rather than our previously one-sided hypothesis. Despite it being much less than before, it is still higher than the type I error rate of 0.05, and we are still unable to reject our new null hypothesis that being in the treatment group results in the same conversion rate as being in the control group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including other factors to our models allows us to detect whether there are other variables that would give us stronger predictions in the resulting dependent variable that we're measuring.  However, if we add additional terms that are incomplete, we may be mislead to make conclusions that don't actually reflect the relationship between the new independent variables and the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now along with testing if the conversion rate changes for different pages, we could also add the factor of which country a user lives in. We'll implement the countries.csv file for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the countries.csv\n",
    "countries = pd.read_csv('countries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with the df2 dataframe\n",
    "df_merged = df2.join(countries.set_index('user_id'),on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the necessary dummy variables\n",
    "df_merged[['CA','UK','US']] = pd.get_dummies(df_merged['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-06-01 10:41</td>       <td>AIC:</td>        <td>212780.8333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212812.5723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9967</td>  <td>0.0068</td>  <td>-292.3145</td> <td>0.0000</td> <td>-2.0101</td> <td>-1.9833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>-0.0408</td>  <td>0.0269</td>   <td>-1.5178</td>  <td>0.1291</td> <td>-0.0935</td> <td>0.0119</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>0.0099</td>   <td>0.0133</td>   <td>0.7458</td>   <td>0.4558</td> <td>-0.0161</td> <td>0.0360</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2022-06-01 10:41 AIC:              212780.8333\n",
       "No. Observations:   290584           BIC:              212812.5723\n",
       "Df Model:           2                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290581           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9967    0.0068  -292.3145  0.0000  -2.0101  -1.9833\n",
       "CA           -0.0408    0.0269    -1.5178  0.1291  -0.0935   0.0119\n",
       "UK            0.0099    0.0133     0.7458  0.4558  -0.0161   0.0360\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does it appear that country had an impact on conversion? \n",
    "\n",
    "#using US as baseline\n",
    "logit_mod = sm.Logit(df_merged['converted'],df_merged[['intercept','CA','UK']])\n",
    "results = logit_mod.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9598291299477989, 1.0100501670841679)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-.041),np.exp(.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the US as our baseline, we see that individuals from CA are 0.96x as likely to convert as individuals from the US, and individuals from the UK are 1.01x as likely to convert as individuals from the US.  Neither P-value for these statistics falls below 0.05, so we fail to reject our new null hypotheses that conversion rates are different between individuals from US vs CA or US vs UK.\n",
    "However, an individual being from UK vs being from CA may have an impact on conversion rate, so we will use the UK as our baseline next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-06-01 10:41</td>       <td>AIC:</td>        <td>212780.8333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212812.5723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9868</td>  <td>0.0114</td>  <td>-174.1736</td> <td>0.0000</td> <td>-2.0092</td> <td>-1.9645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>-0.0099</td>  <td>0.0133</td>   <td>-0.7458</td>  <td>0.4558</td> <td>-0.0360</td> <td>0.0161</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>-0.0507</td>  <td>0.0284</td>   <td>-1.7863</td>  <td>0.0740</td> <td>-0.1064</td> <td>0.0049</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2022-06-01 10:41 AIC:              212780.8333\n",
       "No. Observations:   290584           BIC:              212812.5723\n",
       "Df Model:           2                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290581           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9868    0.0114  -174.1736  0.0000  -2.0092  -1.9645\n",
       "US           -0.0099    0.0133    -0.7458  0.4558  -0.0360   0.0161\n",
       "CA           -0.0507    0.0284    -1.7863  0.0740  -0.1064   0.0049\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using UK as baseline\n",
    "\n",
    "logit_mod = sm.Logit(df_merged['converted'],df_merged[['intercept','US','CA']])\n",
    "results = logit_mod.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95027867053242698"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-.051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using UK as our baseline, we see that individuals from CA are 0.95x as likely to convert.  The p-value for this is the lowest we've seen so far, 0.074, however it is still above our Type I error rate of 0.05, so we still fail to reject our null hypotheses that country has no impact on conversion rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we have now looked at the individual factors of country and page on conversion, we could now like to look at an interaction between page and country to see if are there significant effects on conversion. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged['CA_treatment'] = (df_merged['ab_page'])*(df_merged['CA'])\n",
    "df_merged['UK_treatment'] = (df_merged['ab_page'])*(df_merged['UK'])\n",
    "df_merged['US_treatment'] = (df_merged['ab_page'])*(df_merged['US'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-06-01 10:43</td>       <td>AIC:</td>        <td>212779.0384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212810.7773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>        <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>-1.9963</td>  <td>0.0062</td>  <td>-322.0487</td> <td>0.0000</td> <td>-2.0084</td> <td>-1.9841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_treatment</th> <td>-0.0752</td>  <td>0.0376</td>   <td>-1.9974</td>  <td>0.0458</td> <td>-0.1489</td> <td>-0.0014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_treatment</th> <td>0.0149</td>   <td>0.0173</td>   <td>0.8617</td>   <td>0.3888</td> <td>-0.0190</td> <td>0.0488</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2022-06-01 10:43 AIC:              212779.0384\n",
       "No. Observations:   290584           BIC:              212810.7773\n",
       "Df Model:           2                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290581           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "------------------------------------------------------------------\n",
       "                  Coef.  Std.Err.     z     P>|z|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "intercept        -1.9963   0.0062 -322.0487 0.0000 -2.0084 -1.9841\n",
       "CA_treatment     -0.0752   0.0376   -1.9974 0.0458 -0.1489 -0.0014\n",
       "UK_treatment      0.0149   0.0173    0.8617 0.3888 -0.0190  0.0488\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, we'll use US as a baseline\n",
    "\n",
    "logit_mod = sm.Logit(df_merged['converted'],df_merged[['intercept','CA_treatment','UK_treatment']])\n",
    "results = logit_mod.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.92774348632855286, 1.0151130646157189)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.075),np.exp(0.015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People in the treatment group from the US do not have a statistically significant conversion rate difference when compared to people in the treatment group from the UK. However, not only does the CA_treatment group have a more noticeable difference in conversion rate (0.928 as likely to convert, or almost 8% less likely to convert), the p-value of 0.046 for this rate falls below our type I error rate of 0.05, meaning that we can reject the null hypothesis that the conversion rates between individuals from the US who were given the new page and individuals from CA who were given the new page are no different from each other, in favor of the alternative hypothesis that the conversion rates between these two groups are not the same. \n",
    "\n",
    "Next, we'll use the UK_treatment as our baseline so we may compare the groups UK_treatment and CA_treatment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-06-01 10:43</td>       <td>AIC:</td>        <td>212777.1060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212808.8450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>        <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>-1.9873</td>  <td>0.0072</td>  <td>-275.5728</td> <td>0.0000</td> <td>-2.0014</td> <td>-1.9732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_treatment</th> <td>-0.0842</td>  <td>0.0378</td>   <td>-2.2251</td>  <td>0.0261</td> <td>-0.1583</td> <td>-0.0100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US_treatment</th> <td>-0.0197</td>  <td>0.0121</td>   <td>-1.6337</td>  <td>0.1023</td> <td>-0.0434</td> <td>0.0039</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2022-06-01 10:43 AIC:              212777.1060\n",
       "No. Observations:   290584           BIC:              212808.8450\n",
       "Df Model:           2                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290581           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "------------------------------------------------------------------\n",
       "                  Coef.  Std.Err.     z     P>|z|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "intercept        -1.9873   0.0072 -275.5728 0.0000 -2.0014 -1.9732\n",
       "CA_treatment     -0.0842   0.0378   -2.2251 0.0261 -0.1583 -0.0100\n",
       "US_treatment     -0.0197   0.0121   -1.6337 0.1023 -0.0434  0.0039\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df_merged['converted'],df_merged[['intercept','CA_treatment','US_treatment']])\n",
    "results = logit_mod.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91943125609512466, 0.98019867330675525)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-.084),np.exp(-0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to our comparison between CA_treatment and US_treatment, the subjects from CA who were given the new page had a much lower rate of conversion compared to those from the UK who were also given the new page. The p-value associated with this relationship, 0.026, is much less than the type I error rate of 0.05, and thus we may reject the null hypothesis that the conversion rates between CA_treatment and UK_treatment are the same, in favor of the alternative hypothesis that the conversion rates between these two groups are not the same. \n",
    "\n",
    "Practically speaking, we can conclude that on average, Canadian people offered the new page do not have the same conversion rate as US or UK people who also navigated through the new page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
